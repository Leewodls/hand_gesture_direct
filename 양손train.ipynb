{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05edf38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0f213c33-444f-4c1d-b44d-488046b9d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('dataset/seq_what_1716722114.npy')\n",
    "\n",
    "new_label = 5.00000000e+00  # 새로운 라벨 값으로 변경\n",
    "data[:, :, -1] = new_label\n",
    "\n",
    "np.save('dataset/seq_what_1716722114.npy', data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c71a327-7f7d-4560-bd9b-c1eb48242b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.54358938e-01,  9.03195381e-01,  4.10207441e-08, ...,\n",
       "         1.20741827e-06,  0.00000000e+00,  1.20741827e-06],\n",
       "       [ 1.73739970e-01,  8.48457575e-01,  1.60192428e-07, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.95233285e-01,  7.89771259e-01,  2.91040578e-07, ...,\n",
       "         1.20741827e-06,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.43567309e-01,  5.37320316e-01, -2.81775471e-07, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.46590084e-01,  5.26789427e-01, -2.68394018e-07, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  8.53773646e-07],\n",
       "       [ 1.51645213e-01,  5.10322988e-01, -3.30471721e-07, ...,\n",
       "         8.53773646e-07,  1.20741827e-06,  0.00000000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('dataset/seq_nice_1716725603.npy')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb3cbb51-8d6d-4f6e-ac6a-0e6672480915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 데이터를 불러옵니다.\n",
    "new_data = np.load('dataset/seq_what_1716725603.npy')\n",
    "\n",
    "# 기존 데이터에 새로운 데이터를 추가합니다.\n",
    "existing_data = np.load('dataset/seq_what_1716722114.npy')\n",
    "\n",
    "data = np.concatenate([existing_data, new_data], axis=0)\n",
    "np.save('dataset/seq_what_1716725603.npy', data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbb2ce4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2535, 30, 66)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    'meet', 'nice', 'hello'\n",
    "]\n",
    "\n",
    "data = np.concatenate([\n",
    "    # np.load('dataset/seq_meet_1716721221.npy'),\n",
    "    # np.load('dataset/seq_nice_1716721221.npy'),\n",
    "    # np.load('dataset/seq_hello_1716721221.npy'),\n",
    "    # np.load('dataset/seq_you_1716722114.npy'),\n",
    "    # np.load('dataset/seq_name_1716722114.npy'),\n",
    "    # np.load('dataset/seq_what_1716722114.npy')\n",
    "\n",
    "    np.load('dataset/seq_meet_1716732929.npy'),\n",
    "    np.load('dataset/seq_nice_1716732929.npy'),\n",
    "    np.load('dataset/seq_hello_1716732929.npy'),\n",
    "    # np.load('dataset/seq_you_1716725603.npy'),\n",
    "    # np.load('dataset/seq_name_1716725603.npy'),\n",
    "    # np.load('dataset/seq_what_1716725603.npy')\n",
    "    \n",
    "], axis=0) \n",
    "\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "009ad99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8.29660118e-01  9.58266258e-01 -3.00974932e-07 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 7.83299923e-01  9.87833619e-01 -2.57316373e-07 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 7.46789038e-01  9.83990192e-01 -1.95882336e-07 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [ 7.05835342e-01  8.81330013e-01 -6.17969178e-08 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 6.65639937e-01  8.82690191e-01 -6.52410037e-08 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 6.35008454e-01  8.79838943e-01 -7.78674405e-08 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 7.83299923e-01  9.87833619e-01 -2.57316373e-07 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 7.46789038e-01  9.83990192e-01 -1.95882336e-07 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 7.08663762e-01  9.86680984e-01 -1.61216320e-07 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [ 6.65639937e-01  8.82690191e-01 -6.52410037e-08 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 6.35008454e-01  8.79838943e-01 -7.78674405e-08 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 6.17220402e-01  8.73848438e-01 -9.88015003e-08 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " [[ 7.46789038e-01  9.83990192e-01 -1.95882336e-07 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 7.08663762e-01  9.86680984e-01 -1.61216320e-07 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 6.82709694e-01  9.87818301e-01 -1.96147468e-07 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  ...\n",
      "  [ 6.35008454e-01  8.79838943e-01 -7.78674405e-08 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 6.17220402e-01  8.73848438e-01 -9.88015003e-08 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]\n",
      "  [ 6.07031524e-01  8.67685139e-01 -1.01725938e-07 ...  0.00000000e+00\n",
      "    0.00000000e+00  0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.58343375e-01  7.22961485e-01 -1.73214985e-07 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  [ 1.64106533e-01  7.16488600e-01 -1.72805031e-07 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  [ 1.62313074e-01  7.12678075e-01 -2.90202280e-07 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  ...\n",
      "  [ 1.90456763e-01  6.79836392e-01 -2.46238443e-08 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  [ 1.82887286e-01  6.80106997e-01 -4.11290131e-08 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  [ 1.98430061e-01  6.32851064e-01  4.04999589e-08 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]]\n",
      "\n",
      " [[ 1.64106533e-01  7.16488600e-01 -1.72805031e-07 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  [ 1.62313074e-01  7.12678075e-01 -2.90202280e-07 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  [ 1.64412215e-01  7.09077060e-01 -2.31257658e-07 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  ...\n",
      "  [ 1.82887286e-01  6.80106997e-01 -4.11290131e-08 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  [ 1.98430061e-01  6.32851064e-01  4.04999589e-08 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  [ 2.00626969e-01  6.02446377e-01  8.93620751e-08 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]]\n",
      "\n",
      " [[ 1.62313074e-01  7.12678075e-01 -2.90202280e-07 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  [ 1.64412215e-01  7.09077060e-01 -2.31257658e-07 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  [ 1.64052218e-01  7.02044785e-01 -2.73152892e-07 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  ...\n",
      "  [ 1.98430061e-01  6.32851064e-01  4.04999589e-08 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  [ 2.00626969e-01  6.02446377e-01  8.93620751e-08 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]\n",
      "  [ 2.01143265e-01  5.85926056e-01  1.64032329e-07 ...  2.00000000e+00\n",
      "    1.00000000e+00  2.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ef25a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2535, 21, 65)\n",
      "(2535, 9, 65)\n",
      "(2535,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "right_hand_data = data[:, :21, :-1]  # 오른손 좌표 정보\n",
    "left_hand_data = data[:, 21:, :-1]   # 왼손 좌표 정보\n",
    "action_labels = data[:, 0, -1]       # 동작의 라벨 정보\n",
    "\n",
    "print(right_hand_data.shape)\n",
    "print(left_hand_data.shape)\n",
    "print(action_labels.shape)\n",
    "\n",
    "# 첫 번째 차원 (842): 데이터 포인트의 수 또는 시퀀스의 개수입니다.\n",
    "# 두 번째 차원 (21 또는 9): 각 손의 관절 개수입니다.\n",
    "# 세 번째 차원 (65): 관절의 좌표(x, y, z) 및 가시성을 포함한 속성의 수입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e85a19f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2535, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(action_labels, num_classes=len(actions))\n",
    "\n",
    "y_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13397c97-362a-4737-9c9b-b8d4c98b5b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fa5687d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2281, 30, 65) (2281, 3)\n",
      "(254, 30, 65) (254, 3)\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# x_data = x_data.astype(np.float32)\n",
    "# y_data = y_data.astype(np.float32)\n",
    "\n",
    "# x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "# print(x_train.shape, y_train.shape)\n",
    "# print(x_val.shape, y_val.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = np.concatenate((right_hand_data, left_hand_data), axis=1).astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a399d52-06d4-47e0-95c2-3c6dfef1713f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train의 형태: (2281, 30, 65)\n"
     ]
    }
   ],
   "source": [
    "# print(x_train.shape[2])\n",
    "\n",
    "# x_train의 형태를 확인\n",
    "print(\"x_train의 형태:\", x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2a59f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,459</span> (138.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,459\u001b[0m (138.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,459</span> (138.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,459\u001b[0m (138.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# # model = Sequential([\n",
    "# #     LSTM(64, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2])),\n",
    "# #     Dense(32, activation='relu'),\n",
    "# #     Dense(len(actions), activation='softmax')\n",
    "# # ])\n",
    "\n",
    "# # model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "# # model.summary()\n",
    "\n",
    "\n",
    "# from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# model = Sequential([\n",
    "#     LSTM(64, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2])),   \n",
    "#     Dense(32, activation='relu'),\n",
    "#     Dense(len(actions), activation='softmax')\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31658bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m70/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 0.7876 - loss: 0.5804\n",
      "Epoch 1: val_acc improved from -inf to 1.00000, saving model to models/jm_model.keras\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - acc: 0.7930 - loss: 0.5681 - val_acc: 1.0000 - val_loss: 0.0088 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0048\n",
      "Epoch 2: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0046 - val_acc: 1.0000 - val_loss: 8.4510e-04 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.8551e-04\n",
      "Epoch 3: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.7062e-04 - val_acc: 1.0000 - val_loss: 3.2184e-04 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m62/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.8664e-04\n",
      "Epoch 4: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.7744e-04 - val_acc: 1.0000 - val_loss: 1.7437e-04 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4030e-04\n",
      "Epoch 5: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3914e-04 - val_acc: 1.0000 - val_loss: 1.0787e-04 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.1141e-05\n",
      "Epoch 6: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.0488e-05 - val_acc: 1.0000 - val_loss: 7.4219e-05 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.6244e-05\n",
      "Epoch 7: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.5645e-05 - val_acc: 1.0000 - val_loss: 5.3289e-05 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.5930e-05\n",
      "Epoch 8: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.5705e-05 - val_acc: 1.0000 - val_loss: 4.0879e-05 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m62/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.5132e-05\n",
      "Epoch 9: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.4890e-05 - val_acc: 1.0000 - val_loss: 3.1937e-05 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.5718e-05\n",
      "Epoch 10: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.5814e-05 - val_acc: 1.0000 - val_loss: 2.5619e-05 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.3113e-05\n",
      "Epoch 11: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.2962e-05 - val_acc: 1.0000 - val_loss: 2.1057e-05 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m65/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8319e-05\n",
      "Epoch 12: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8260e-05 - val_acc: 1.0000 - val_loss: 1.7649e-05 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6280e-05\n",
      "Epoch 13: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6171e-05 - val_acc: 1.0000 - val_loss: 1.4931e-05 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4396e-05\n",
      "Epoch 14: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4373e-05 - val_acc: 1.0000 - val_loss: 1.2826e-05 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m65/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1149e-05\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1139e-05 - val_acc: 1.0000 - val_loss: 1.1084e-05 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m62/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0173e-05\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0050e-05 - val_acc: 1.0000 - val_loss: 9.6977e-06 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m63/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.4209e-06\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.5353e-06 - val_acc: 1.0000 - val_loss: 8.5301e-06 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m62/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.3610e-06\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.1967e-06 - val_acc: 1.0000 - val_loss: 7.5010e-06 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.1678e-06\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.1716e-06 - val_acc: 1.0000 - val_loss: 6.6806e-06 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.7329e-06\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.7194e-06 - val_acc: 1.0000 - val_loss: 5.9776e-06 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.1597e-06\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.1601e-06 - val_acc: 1.0000 - val_loss: 5.3652e-06 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.0306e-06\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.9992e-06 - val_acc: 1.0000 - val_loss: 4.8302e-06 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m65/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.7076e-06\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.7597e-06 - val_acc: 1.0000 - val_loss: 4.3923e-06 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m61/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.8810e-06\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.8677e-06 - val_acc: 1.0000 - val_loss: 3.9864e-06 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.2503e-06\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.2669e-06 - val_acc: 1.0000 - val_loss: 3.6382e-06 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.9876e-06\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.0025e-06 - val_acc: 1.0000 - val_loss: 3.3265e-06 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m62/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.8213e-06\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.8153e-06 - val_acc: 1.0000 - val_loss: 3.0478e-06 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.8022e-06\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.7834e-06 - val_acc: 1.0000 - val_loss: 2.7878e-06 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.5590e-06\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.5454e-06 - val_acc: 1.0000 - val_loss: 2.5611e-06 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.3276e-06\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.3262e-06 - val_acc: 1.0000 - val_loss: 2.3626e-06 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9622e-06\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.9680e-06 - val_acc: 1.0000 - val_loss: 2.1894e-06 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6927e-06\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.7059e-06 - val_acc: 1.0000 - val_loss: 2.0261e-06 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5737e-06\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5879e-06 - val_acc: 1.0000 - val_loss: 1.8717e-06 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m64/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6142e-06\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6147e-06 - val_acc: 1.0000 - val_loss: 1.7360e-06 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m62/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4145e-06\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4220e-06 - val_acc: 1.0000 - val_loss: 1.6140e-06 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4051e-06\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.4044e-06 - val_acc: 1.0000 - val_loss: 1.5004e-06 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.2610e-06\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.2656e-06 - val_acc: 1.0000 - val_loss: 1.4019e-06 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.2727e-06\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.2713e-06 - val_acc: 1.0000 - val_loss: 1.3104e-06 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m70/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1997e-06\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1972e-06 - val_acc: 1.0000 - val_loss: 1.2292e-06 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m65/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1127e-06\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1088e-06 - val_acc: 1.0000 - val_loss: 1.1522e-06 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.6195e-07\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.6571e-07 - val_acc: 1.0000 - val_loss: 1.0809e-06 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.9498e-07\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 9.9420e-07 - val_acc: 1.0000 - val_loss: 1.0086e-06 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m64/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.6580e-07\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.5512e-07 - val_acc: 1.0000 - val_loss: 9.4287e-07 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m70/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.1730e-07\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.1756e-07 - val_acc: 1.0000 - val_loss: 8.8749e-07 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.5054e-07\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.4844e-07 - val_acc: 1.0000 - val_loss: 8.3681e-07 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.1567e-07\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.1655e-07 - val_acc: 1.0000 - val_loss: 7.8894e-07 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m62/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.2820e-07\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.3548e-07 - val_acc: 1.0000 - val_loss: 7.4623e-07 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m69/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.1895e-07\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.1498e-07 - val_acc: 1.0000 - val_loss: 6.9742e-07 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.8913e-07\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.8250e-07 - val_acc: 1.0000 - val_loss: 6.5753e-07 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m65/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.6397e-07\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.6450e-07 - val_acc: 1.0000 - val_loss: 6.1716e-07 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.2877e-07\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.2988e-07 - val_acc: 1.0000 - val_loss: 5.8243e-07 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.4750e-07\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.4658e-07 - val_acc: 1.0000 - val_loss: 5.6366e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.7687e-07\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.7821e-07 - val_acc: 1.0000 - val_loss: 5.4676e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m65/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.7849e-07\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.7831e-07 - val_acc: 1.0000 - val_loss: 5.3269e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.9248e-07\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.9073e-07 - val_acc: 1.0000 - val_loss: 5.1579e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m64/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.8610e-07\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.8293e-07 - val_acc: 1.0000 - val_loss: 5.0218e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.6142e-07\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.6917e-07 - val_acc: 1.0000 - val_loss: 4.8434e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m65/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.9353e-07\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.9632e-07 - val_acc: 1.0000 - val_loss: 4.7120e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 59/100\n",
      "\u001b[1m62/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.2871e-07\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.2422e-07 - val_acc: 1.0000 - val_loss: 4.5525e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.2112e-07\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.2084e-07 - val_acc: 1.0000 - val_loss: 4.4023e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.0685e-07\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.0474e-07 - val_acc: 1.0000 - val_loss: 4.2568e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.9622e-07\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.9592e-07 - val_acc: 1.0000 - val_loss: 4.1442e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 63/100\n",
      "\u001b[1m69/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.7334e-07\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.7279e-07 - val_acc: 1.0000 - val_loss: 3.9940e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m70/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.9445e-07\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.9265e-07 - val_acc: 1.0000 - val_loss: 3.8438e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m64/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.0856e-07\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.1239e-07 - val_acc: 1.0000 - val_loss: 3.7030e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 3.3053e-07\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.3046e-07 - val_acc: 1.0000 - val_loss: 3.5575e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m68/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.9136e-07\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.9305e-07 - val_acc: 1.0000 - val_loss: 3.4496e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7204e-07\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7454e-07 - val_acc: 1.0000 - val_loss: 3.3369e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m69/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.7076e-07\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7188e-07 - val_acc: 1.0000 - val_loss: 3.1961e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m62/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.9635e-07\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.9372e-07 - val_acc: 1.0000 - val_loss: 3.0600e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.3165e-07\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.3269e-07 - val_acc: 1.0000 - val_loss: 2.9615e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m69/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.8238e-07\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.8108e-07 - val_acc: 1.0000 - val_loss: 2.8300e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.4858e-07\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.4817e-07 - val_acc: 1.0000 - val_loss: 2.7174e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m68/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7355e-07\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7105e-07 - val_acc: 1.0000 - val_loss: 2.6188e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.5239e-07\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.5161e-07 - val_acc: 1.0000 - val_loss: 2.4827e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m64/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8370e-07\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.8730e-07 - val_acc: 1.0000 - val_loss: 2.3560e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m63/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.4174e-07\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.3705e-07 - val_acc: 1.0000 - val_loss: 2.2387e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m69/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 2.2286e-07\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.2137e-07 - val_acc: 1.0000 - val_loss: 2.1307e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7599e-07\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.7680e-07 - val_acc: 1.0000 - val_loss: 2.0416e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.5595e-07\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5644e-07 - val_acc: 1.0000 - val_loss: 1.9242e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m62/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.5468e-07\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5596e-07 - val_acc: 1.0000 - val_loss: 1.8210e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m70/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.6474e-07\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.6429e-07 - val_acc: 1.0000 - val_loss: 1.7084e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.5305e-07\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.5280e-07 - val_acc: 1.0000 - val_loss: 1.6004e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3214e-07\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3220e-07 - val_acc: 1.0000 - val_loss: 1.5018e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m70/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.3528e-07\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.3485e-07 - val_acc: 1.0000 - val_loss: 1.4033e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.1102e-07\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.1112e-07 - val_acc: 1.0000 - val_loss: 1.3000e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.9397e-08\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 9.9492e-08 - val_acc: 1.0000 - val_loss: 1.1921e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m70/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 1.0122e-07\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 1.0108e-07 - val_acc: 1.0000 - val_loss: 1.1029e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m69/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.7866e-08\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.7985e-08 - val_acc: 1.0000 - val_loss: 1.0184e-07 - learning_rate: 5.0000e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m71/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 8.5175e-08\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 8.5083e-08 - val_acc: 1.0000 - val_loss: 9.3866e-08 - learning_rate: 5.0000e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 7.2255e-08\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 7.2290e-08 - val_acc: 1.0000 - val_loss: 8.5418e-08 - learning_rate: 5.0000e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m62/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 6.7995e-08\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.8017e-08 - val_acc: 1.0000 - val_loss: 7.7439e-08 - learning_rate: 5.0000e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.3454e-08\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.3550e-08 - val_acc: 1.0000 - val_loss: 7.1807e-08 - learning_rate: 5.0000e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.0929e-08\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.1325e-08 - val_acc: 1.0000 - val_loss: 6.5237e-08 - learning_rate: 5.0000e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.3779e-08\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.3449e-08 - val_acc: 1.0000 - val_loss: 6.0074e-08 - learning_rate: 5.0000e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m70/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 5.6653e-08\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 5.6138e-08 - val_acc: 1.0000 - val_loss: 5.4442e-08 - learning_rate: 5.0000e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m70/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 4.5099e-08\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 4.4883e-08 - val_acc: 1.0000 - val_loss: 5.1157e-08 - learning_rate: 5.0000e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.7122e-08\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.7001e-08 - val_acc: 1.0000 - val_loss: 4.5055e-08 - learning_rate: 5.0000e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m66/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5715e-08\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 3.5363e-08 - val_acc: 1.0000 - val_loss: 4.1770e-08 - learning_rate: 5.0000e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m67/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7320e-08\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 2.7437e-08 - val_acc: 1.0000 - val_loss: 3.8954e-08 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/jm_model.keras', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9077c0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "212c2858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[175,   0],\n",
       "        [  0,  79]],\n",
       "\n",
       "       [[166,   0],\n",
       "        [  0,  88]],\n",
       "\n",
       "       [[167,   0],\n",
       "        [  0,  87]]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model1 = load_model('models/jm_model.keras')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2377e-b8f9-4de3-9777-f170bb8ccd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
